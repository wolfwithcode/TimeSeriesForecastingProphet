{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Your own AutoML.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPPrHBEcAK/MW/yuy8vwq/s"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6g-tZZaY0mmq"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer, make_column_selector\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, OneHotEncoder\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import LinearSVC,SVC\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.metrics import balanced_accuracy_score"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qcc4K-M8nTI"
      },
      "source": [
        "class MyAutoMLClassifier:\n",
        "  def __init__(self, scoring_function = 'balanced_accuracy', n_iter = 50):\n",
        "    self.scoring_function = scoring_function\n",
        "    self.n_iter = n_iter\n",
        "  \n",
        "  def fit(self,X,y):\n",
        "    X_train = X\n",
        "    y_train = y\n",
        "\n",
        "    categorical_values = []\n",
        "\n",
        "    cat_subset = X_train.select_dtypes(include = ['object','category','bool'])\n",
        "\n",
        "    for i in range(cat_subset.shape[1]):\n",
        "      categorical_values.append(list(cat_subset.iloc[:,i].dropna().unique()))\n",
        "\n",
        "    num_pipeline = Pipeline([\n",
        "                         ('cleaner',SimpleImputer()),\n",
        "                         ('scaler',StandardScaler())\n",
        "                         ])\n",
        "\n",
        "    cat_pipeline = Pipeline([\n",
        "                        ('cleaner',SimpleImputer(strategy = 'most_frequent')),\n",
        "                        ('encoder',OneHotEncoder(sparse = False, categories=categorical_values))\n",
        "    ])\n",
        "\n",
        "\n",
        "    preprocessor = ColumnTransformer([\n",
        "      ('numerical', num_pipeline, make_column_selector(dtype_exclude=['object','category','bool'])),\n",
        "      ('categorical', cat_pipeline, make_column_selector(dtype_include=['object','category','bool']))\n",
        "    ])\n",
        "\n",
        "    model_pipeline_steps = []\n",
        "    model_pipeline_steps.append(('preprocessor',preprocessor))\n",
        "    model_pipeline_steps.append(('feature_selector',SelectKBest(f_classif,k='all')))\n",
        "    model_pipeline_steps.append(('estimator',LogisticRegression()))\n",
        "    model_pipeline = Pipeline(model_pipeline_steps)\n",
        "\n",
        "    total_features = preprocessor.fit_transform(X_train).shape[1]\n",
        "\n",
        "    optimization_grid = []\n",
        "\n",
        "    # Logistic regression\n",
        "    optimization_grid.append({\n",
        "        'preprocessor__numerical__scaler':[RobustScaler(),StandardScaler(),MinMaxScaler()],\n",
        "        'preprocessor__numerical__cleaner__strategy':['mean','median'],\n",
        "        'feature_selector__k': list(np.arange(1,total_features,5)) + ['all'],\n",
        "        'estimator':[LogisticRegression()]\n",
        "    })\n",
        "\n",
        "    # K-nearest neighbors\n",
        "    optimization_grid.append({\n",
        "        'preprocessor__numerical__scaler':[RobustScaler(),StandardScaler(),MinMaxScaler()],\n",
        "        'preprocessor__numerical__cleaner__strategy':['mean','median'],\n",
        "        'feature_selector__k': list(np.arange(1,total_features,5)) + ['all'],\n",
        "        'estimator':[KNeighborsClassifier()],\n",
        "        'estimator__weights':['uniform','distance'],\n",
        "        'estimator__n_neighbors':np.arange(1,20,1)\n",
        "    })\n",
        "\n",
        "    # Random Forest\n",
        "    optimization_grid.append({\n",
        "        'preprocessor__numerical__scaler':[None],\n",
        "        'preprocessor__numerical__cleaner__strategy':['mean','median'],\n",
        "        'feature_selector__k': list(np.arange(1,total_features,5)) + ['all'],\n",
        "        'estimator':[RandomForestClassifier(random_state=0)],\n",
        "        'estimator__n_estimators':np.arange(5,500,10),\n",
        "        'estimator__criterion':['gini','entropy']\n",
        "    })\n",
        "\n",
        "\n",
        "    # Gradient boosting\n",
        "    optimization_grid.append({\n",
        "        'preprocessor__numerical__scaler':[None],\n",
        "        'preprocessor__numerical__cleaner__strategy':['mean','median'],\n",
        "        'feature_selector__k': list(np.arange(1,total_features,5)) + ['all'],\n",
        "        'estimator':[GradientBoostingClassifier(random_state=0)],\n",
        "        'estimator__n_estimators':np.arange(5,500,10),\n",
        "        'estimator__learning_rate':np.linspace(0.1,0.9,20),\n",
        "    })\n",
        "\n",
        "\n",
        "\n",
        "    # Decision tree\n",
        "    optimization_grid.append({\n",
        "        'preprocessor__numerical__scaler':[None],\n",
        "        'preprocessor__numerical__cleaner__strategy':['mean','median'],\n",
        "        'feature_selector__k': list(np.arange(1,total_features,5)) + ['all'],\n",
        "        'estimator':[DecisionTreeClassifier(random_state=0)],\n",
        "        'estimator__criterion':['gini','entropy']\n",
        "    })\n",
        "\n",
        "    # Linear SVM\n",
        "    optimization_grid.append({\n",
        "        'preprocessor__numerical__scaler':[RobustScaler(),StandardScaler(),MinMaxScaler()],\n",
        "        'preprocessor__numerical__cleaner__strategy':['mean','median'],\n",
        "        'feature_selector__k': list(np.arange(1,total_features,5)) + ['all'],\n",
        "        'estimator':[LinearSVC(random_state = 0)],\n",
        "        'estimator__C': np.arange(0.1,1,0.1),\n",
        "        \n",
        "    })\n",
        "\n",
        "    search = RandomizedSearchCV(\n",
        "      model_pipeline,\n",
        "      optimization_grid,\n",
        "      n_iter=self.n_iter,\n",
        "      scoring = self.scoring_function, \n",
        "      n_jobs = -1, \n",
        "      random_state = 0, \n",
        "      verbose = 3,\n",
        "      cv = 5\n",
        "    )\n",
        "\n",
        "    search.fit(X_train, y_train)\n",
        "    self.best_estimator_ = search.best_estimator_\n",
        "    self.best_pipeline = search.best_params_\n",
        "    \n",
        "\n",
        "  \n",
        "  def predict(self,X,y = None):\n",
        "    return self.best_estimator_.predict(X)\n",
        "\n",
        "  def predict_proba(self,X,y = None):\n",
        "    return self.best_estimator_.predict_proba(X)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIJERMw9FPtf"
      },
      "source": [
        "d = load_breast_cancer()\n",
        "y = d['target']\n",
        "X = pd.DataFrame(d['data'],columns = d['feature_names'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "model = MyAutoMLClassifier()\n",
        "model.fit(X_train,y_train)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fR1Xa8H-TzW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0379f05e-5607-4061-f30b-a939254a845f"
      },
      "source": [
        "balanced_accuracy_score(y_test, model.predict(X_test))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9428271863821389"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQjT-9OE_c-L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca94334f-d9eb-4447-9dd5-653bfa0adff3"
      },
      "source": [
        "model.best_pipeline"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'estimator': GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
              "                            learning_rate=0.1, loss='deviance', max_depth=3,\n",
              "                            max_features=None, max_leaf_nodes=None,\n",
              "                            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                            min_samples_leaf=1, min_samples_split=2,\n",
              "                            min_weight_fraction_leaf=0.0, n_estimators=125,\n",
              "                            n_iter_no_change=None, presort='deprecated',\n",
              "                            random_state=0, subsample=1.0, tol=0.0001,\n",
              "                            validation_fraction=0.1, verbose=0,\n",
              "                            warm_start=False),\n",
              " 'estimator__learning_rate': 0.1,\n",
              " 'estimator__n_estimators': 125,\n",
              " 'feature_selector__k': 'all',\n",
              " 'preprocessor__numerical__cleaner__strategy': 'median',\n",
              " 'preprocessor__numerical__scaler': None}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iFNVZjeACCv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}